{
  "en": {
    "page_title": "Transformer ChatGPT Visual",
    "title": "ğŸ¤– Transformer ChatGPT Visual",
    "sidebar_header": "Parameter Settings",
    "user_input": "Enter query:",
    "max_chars_help": "Maximum 200 characters",
    "temperature": "Temperature",
    "temperature_help": "Controls the randomness of generated text, higher values are more random",
    "top_p": "Top-p (Nucleus Sampling)",
    "top_p_help": "Controls the probability threshold for nucleus sampling",
    "top_k": "Top-k",
    "top_k_help": "Number of highest probability tokens to consider during generation",
    "max_new_tokens": "Max New Tokens",
    "max_new_tokens_help": "Maximum number of tokens to generate",
    "processing_steps": "Processing Steps",
    "basic_steps": "Basic Processing Steps",
    "tokenization": "1. Tokenization",
    "encoding": "2. Encoding",
    "vectorization": "3. Vectorization",
    "normalization": "4. Normalization",
    "correlation": "5. Correlation Calculation",
    "generation": "6. Generation",
    "advanced_features": "Advanced Features",
    "enable_advanced": "Enable Advanced Features",
    "mcp": "7. MCP (Model Context Processing)",
    "skill": "8. Skill (Tool Calling)",
    "rag": "9. RAG (Retrieval-Augmented Generation)",
    "process_button": "Process",
    "processing": "Processing...",
    "tokenization_tip": "ğŸ’¡ **Tip:** Tokenization is the process of breaking continuous text into meaningful basic units (tokens), which is the first step in NLP processing.",
    "original_input": "**Original Input:**",
    "tokenization_result": "**Tokenization Result:**",
    "tokenization_visualization": "**Tokenization Visualization:**",
    "encoding_tip": "ğŸ’¡ **Tip:** Encoding converts tokenization results into numerical IDs that the model can understand.",
    "token_ids": "**Token IDs:**",
    "token_id_mapping": "**Token to ID Mapping:**",
    "vectorization_tip": "ğŸ’¡ **Tip:** Vectorization converts discrete token IDs into continuous vector representations.",
    "token_to_vector": "Token to Vector Conversion Process",
    "word_embedding": "1. **Word Embedding Layer**: Each token ID is mapped to a fixed-dimensional vector through an embedding matrix",
    "positional_embedding": "2. **Positional Embedding**: Add positional information to help the model understand token order",
    "layer_norm": "3. **Layer Normalization**: Normalize vectors",
    "multi_head_attention": "4. **Multi-Head Attention**: Calculate relationships between tokens using self-attention mechanism",
    "feed_forward": "5. **Feed-Forward Network**: Apply non-linear transformation to attention output",
    "dot_product_visualization": "ğŸ”¢ Dot Product Calculation Visualization",
    "dot_product_desc": "Dot product is the core calculation in Transformer attention mechanism, used to measure the similarity between two vectors:",
    "vector_a": "**Vector A:**",
    "vector_b": "**Vector B:**",
    "dot_product_result": "**Dot Product Result:**",
    "dot_product_calc": "Calculation: (0.5 Ã— 0.3) + (0.7 Ã— 0.6) + (0.2 Ã— 0.9) = 0.15 + 0.42 + 0.18 = 0.75",
    "softmax_activation": "ğŸ“ˆ Softmax Activation Function",
    "softmax_tip": "ğŸ’¡ **Tip:** Softmax function converts a set of arbitrary real numbers into a probability distribution between 0 and 1, with all output values summing to 1.",
    "input_logits": "**Input Logits:**",
    "exponential_transform": "**Exponential Transformation:**",
    "sum_result": "**Sum:**",
    "softmax_probs": "**Softmax Probabilities:**",
    "probability_sum": "**Probability Sum:**",
    "attention_visualization": "ğŸ‘ï¸ Attention Relationship Visualization",
    "attention_tip": "ğŸ’¡ **Tip:** Attention weights show how much the model focuses on other tokens when processing each token. Darker colors indicate higher attention weights.",
    "attention_heads": "**Number of Attention Heads:**",
    "attention_matrix": "**Attention Weights Heatmap for Head {head_num}:**",
    "attention_cell_desc": "Each cell represents the attention weight from the row token to the column token",
    "max_attention": "**Maximum Attention Weight:** {max_attn:.4f} (Token {token_from} â†’ Token {token_to})",
    "final_vector": "Final Vector Representation",
    "vector_dimension": "**Vector Dimension:**",
    "vector_first_20": "**First 20 Vector Elements:**",
    "vector_stats": "**Vector Statistics:**",
    "min_value": "Min",
    "max_value": "Max",
    "mean_value": "Mean",
    "std_value": "Std",
    "normalization_tip": "ğŸ’¡ **Tip:** Normalization scales vectors to a fixed norm, usually using L2 normalization (Euclidean norm).",
    "norm_before": "**Vector Norm Before Normalization:**",
    "norm_after": "**Vector Norm After Normalization:**",
    "normalized_vector": "**Normalized Vector First 20 Elements:**",
    "norm_comparison": "**Normalization Comparison:**",
    "before_normalization": "Before Normalization:",
    "after_normalization": "After Normalization:",
    "correlation_tip": "ğŸ’¡ **Tip:** Correlation calculation measures the similarity between input text and other texts or categories.",
    "correlation_with_categories": "**Correlation with Example Categories:**",
    "most_relevant": "**Most Relevant Category:** {most_relevant} (Similarity: {similarity_value:.4f})",
    "classification_tip": "ğŸ’¡ **Tip:** BERT is a powerful encoder model that can be used for various downstream tasks through its output vector representations.",
    "bert_analysis": "**BERT Model Analysis Results:**",
    "bert_info": "BERT is an encoder model that does not support text generation, but can be used for text classification, vector generation, etc.\n\nCurrent implementation uses BERT for:\n1. Chinese tokenization\n2. Text encoding\n3. Vector generation\n4. Vector normalization\n5. Correlation calculation",
    "vector_applications": "**Input Text Vector Representation Can Be Used For:**",
    "similarity_calc": "- Text similarity calculation",
    "text_classification": "- Text classification",
    "information_retrieval": "- Information retrieval",
    "clustering": "- Clustering analysis",
    "recommendation": "- Recommendation systems",
    "mcp_tip": "ğŸ’¡ **Tip:** MCP (Model Context Processing) optimizes model inputs to improve understanding and generation quality.",
    "mcp_process": "MCP Processing Flow",
    "context_acquisition": "### 1. Context Acquisition",
    "context_acquisition_desc": "- Extract relevant context from dialogue history\n- Identify key information and topics\n- Filter irrelevant content",
    "context_optimization": "### 2. Context Optimization",
    "context_optimization_desc": "- Reorder context information\n- Compress long context\n- Add task instructions",
    "context_injection": "### 3. Context Injection",
    "context_injection_desc": "- Input optimized context into the model\n- Ensure context is relevant to current query\n- Control context length",
    "mcp_example": "MCP Example Demonstration",
    "original_context": "**Original Context:**",
    "optimized_context": "**Optimized Context:**",
    "mcp_advantages": "**MCP Advantages:**",
    "mcp_advantage1": "- Improve model understanding of long context",
    "mcp_advantage2": "- Reduce model attention dispersion",
    "mcp_advantage3": "- Improve relevance and accuracy of generated content",
    "mcp_advantage4": "- Reduce model computational cost",
    "skill_tip": "ğŸ’¡ **Tip:** Skill calling allows the model to use external tools and APIs as needed to extend its capabilities.",
    "skill_process": "Skill Calling Flow",
    "intent_recognition": "### 1. Intent Recognition",
    "intent_recognition_desc": "The model identifies that a specific skill is needed for the user's request",
    "skill_selection": "### 2. Skill Selection",
    "skill_selection_desc": "Select appropriate skills based on request type",
    "parameter_extraction": "### 3. Parameter Extraction",
    "parameter_extraction_desc": "Extract required parameters for the skill from user input",
    "skill_execution": "### 4. Skill Execution",
    "skill_execution_desc": "Call external skills and obtain results",
    "result_integration": "### 5. Result Integration",
    "result_integration_desc": "Integrate skill results into model response",
    "skill_examples": "Skill Examples",
    "available_skills": "**Available Skills List:**",
    "skill_demonstration": "Skill Calling Demonstration",
    "user_request": "**User Request:**",
    "selected_skill": "**Selected Skill:**",
    "skill_parameters": "**Skill Parameters:**",
    "skill_result": "**Skill Result:**",
    "final_response": "**Final Response:**",
    "rag_tip": "ğŸ’¡ **Tip:** RAG (Retrieval-Augmented Generation) combines information retrieval and generative AI to enhance the accuracy and reliability of model-generated content.",
    "rag_process": "RAG Processing Flow",
    "rag_components": "### RAG Core Components",
    "retriever": "1. **Retriever** - Retrieve relevant information from document library",
    "generator": "2. **Generator** - Generate responses based on retrieval results",
    "document_library": "3. **Document Library** - Store structured and unstructured data",
    "indexer": "4. **Indexer** - Build efficient document indexes",
    "rag_workflow": "### RAG Workflow",
    "rag_workflow1": "1. Receive user query",
    "rag_workflow2": "2. Convert query to vector representation",
    "rag_workflow3": "3. Retrieve relevant documents from query",
    "rag_workflow4": "4. Input retrieval results and query into model",
    "rag_workflow5": "5. Generate enhanced response",
    "rag_visualization": "RAG Flow Visualization",
    "rag_example": "RAG Example Demonstration",
    "rag_query": "**User Query:**",
    "retrieved_documents": "**Retrieved Relevant Documents:**",
    "rag_advantages": "**RAG Advantages:**",
    "rag_advantage1": "- Improve accuracy and reliability of generated content",
    "rag_advantage2": "- Allow models to access latest and domain-specific information",
    "rag_advantage3": "- Reduce model hallucinations and misinformation",
    "rag_advantage4": "- Support citation and traceability of generated content",
    "processing_completed": "Processing Completed!",
    "all_steps_completed": "All processing steps have been completed!",
    "tokenization_complete": "Completed Tokenization",
    "encoding_complete": "Completed Encoding",
    "vectorization_complete": "Completed Vectorization",
    "normalization_complete": "Completed Normalization",
    "correlation_complete": "Completed Correlation Calculation",
    "generation_complete": "Completed Generation",
    "mcp_complete": "Completed MCP Processing",
    "skill_complete": "Completed Skill Calling",
    "rag_complete": "Completed RAG Demonstration"
  },
  "zh": {
    "page_title": "Transformer ChatGPT å¯è§†åŒ–",
    "title": "ğŸ¤– Transformer ChatGPT å¯è§†åŒ–",
    "sidebar_header": "å‚æ•°è®¾ç½®",
    "user_input": "è¾“å…¥æŸ¥è¯¢å†…å®¹:",
    "max_chars_help": "æœ€å¤šè¾“å…¥200ä¸ªå­—ç¬¦",
    "temperature": "æ¸©åº¦ (Temperature)",
    "temperature_help": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¶Šéšæœº",
    "top_p": "Top-p (Nucleus Sampling)",
    "top_p_help": "æ§åˆ¶æ ¸é‡‡æ ·çš„æ¦‚ç‡é˜ˆå€¼",
    "top_k": "Top-k",
    "top_k_help": "æ¯æ¬¡ç”Ÿæˆæ—¶è€ƒè™‘çš„æœ€é«˜æ¦‚ç‡tokenæ•°é‡",
    "max_new_tokens": "æœ€å¤§æ–°ç”Ÿæˆtokenæ•°",
    "max_new_tokens_help": "ç”Ÿæˆçš„æœ€å¤§tokenæ•°é‡",
    "processing_steps": "å¤„ç†æ­¥éª¤",
    "basic_steps": "åŸºç¡€å¤„ç†æ­¥éª¤",
    "tokenization": "1. åˆ†è¯å¤„ç†",
    "encoding": "2. ç¼–ç è½¬æ¢",
    "vectorization": "3. å‘é‡åŒ–",
    "normalization": "4. å½’ä¸€åŒ–",
    "correlation": "5. ç›¸å…³æ€§è®¡ç®—",
    "generation": "6. ç”Ÿæˆå“åº”",
    "advanced_features": "é«˜çº§åŠŸèƒ½æ¼”ç¤º",
    "enable_advanced": "å¯ç”¨é«˜çº§åŠŸèƒ½",
    "mcp": "7. MCP (æ¨¡å‹ä¸Šä¸‹æ–‡å¤„ç†)",
    "skill": "8. Skill (æŠ€èƒ½è°ƒç”¨)",
    "rag": "9. RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)",
    "process_button": "å¼€å§‹å¤„ç†",
    "processing": "æ­£åœ¨å¤„ç†...",
    "tokenization_tip": "ğŸ’¡ **Tip:** åˆ†è¯æ˜¯å°†è¿ç»­æ–‡æœ¬åˆ†è§£ä¸ºæœ‰æ„ä¹‰çš„åŸºæœ¬å•ä½ï¼ˆtokenï¼‰çš„è¿‡ç¨‹ï¼Œæ˜¯NLPå¤„ç†çš„ç¬¬ä¸€æ­¥ã€‚BERTé‡‡ç”¨WordPieceåˆ†è¯ï¼Œèƒ½å¾ˆå¥½åœ°å¤„ç†æœªç™»å½•è¯å’Œå¤šè¯­è¨€æ–‡æœ¬ã€‚",
    "original_input": "**åŸå§‹è¾“å…¥:**",
    "tokenization_result": "**åˆ†è¯ç»“æœ:**",
    "tokenization_visualization": "**åˆ†è¯å¯è§†åŒ–:**",
    "encoding_tip": "ğŸ’¡ **Tip:** ç¼–ç è½¬æ¢æ˜¯å°†åˆ†è¯ç»“æœè½¬æ¢ä¸ºæ¨¡å‹å¯ç†è§£çš„æ•°å­—IDçš„è¿‡ç¨‹ã€‚æ¯ä¸ªtokenéƒ½æœ‰å¯¹åº”çš„å”¯ä¸€IDï¼Œå­˜å‚¨åœ¨æ¨¡å‹çš„è¯æ±‡è¡¨ä¸­ï¼Œæ–¹ä¾¿æ¨¡å‹è¿›è¡Œæ•°å€¼è®¡ç®—ã€‚",
    "token_ids": "**Token IDs:**",
    "token_id_mapping": "**åˆ†è¯ä¸IDå¯¹åº”å…³ç³»:**",
    "vectorization_tip": "ğŸ’¡ **Tip:** å‘é‡åŒ–æ˜¯å°†ç¦»æ•£çš„token IDè½¬æ¢ä¸ºè¿ç»­çš„å‘é‡è¡¨ç¤ºçš„è¿‡ç¨‹ã€‚BERTä½¿ç”¨åµŒå…¥å±‚å°†æ¯ä¸ªtoken IDæ˜ å°„åˆ°é«˜ç»´å‘é‡ç©ºé—´ï¼Œç„¶åé€šè¿‡å¤šå±‚Transformerç¼–ç å™¨ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å‘é‡è¡¨ç¤ºã€‚",
    "token_to_vector": "Tokenåˆ°å‘é‡çš„è½¬æ¢è¿‡ç¨‹",
    "word_embedding": "1. **è¯åµŒå…¥å±‚**ï¼šæ¯ä¸ªtoken IDé€šè¿‡åµŒå…¥çŸ©é˜µæ˜ å°„åˆ°å›ºå®šç»´åº¦çš„å‘é‡",
    "positional_embedding": "2. **ä½ç½®åµŒå…¥**ï¼šæ·»åŠ ä½ç½®ä¿¡æ¯ï¼Œä½¿æ¨¡å‹ç†è§£tokené¡ºåº",
    "layer_norm": "3. **å±‚å½’ä¸€åŒ–**ï¼šå¯¹å‘é‡è¿›è¡Œå½’ä¸€åŒ–å¤„ç†",
    "multi_head_attention": "4. **å¤šå¤´æ³¨æ„åŠ›**ï¼šé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶è®¡ç®—tokené—´çš„å…³ç³»",
    "feed_forward": "5. **å‰é¦ˆç½‘ç»œ**ï¼šå¯¹æ³¨æ„åŠ›è¾“å‡ºè¿›è¡Œéçº¿æ€§å˜æ¢",
    "dot_product_visualization": "ğŸ”¢ ç‚¹ç§¯è®¡ç®—å¯è§†åŒ–",
    "dot_product_desc": "ç‚¹ç§¯æ˜¯Transformeræ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒè®¡ç®—ï¼Œç”¨äºè¡¡é‡ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦ï¼š",
    "vector_a": "**å‘é‡A:**",
    "vector_b": "**å‘é‡B:**",
    "dot_product_result": "**ç‚¹ç§¯ç»“æœ:**",
    "dot_product_calc": "è®¡ç®—è¿‡ç¨‹ï¼š(0.5 Ã— 0.3) + (0.7 Ã— 0.6) + (0.2 Ã— 0.9) = 0.15 + 0.42 + 0.18 = 0.75",
    "softmax_activation": "ğŸ“ˆ Softmaxæ¿€æ´»å‡½æ•°",
    "softmax_tip": "ğŸ’¡ **Tip:** Softmaxå‡½æ•°å°†ä¸€ç»„ä»»æ„å®æ•°è½¬æ¢ä¸ºä»‹äº0å’Œ1ä¹‹é—´çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ‰€æœ‰è¾“å‡ºå€¼ä¹‹å’Œä¸º1ï¼Œå¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡çš„è¾“å‡ºå±‚ã€‚",
    "input_logits": "**è¾“å…¥logits:**",
    "exponential_transform": "**æŒ‡æ•°è½¬æ¢:**",
    "sum_result": "**æ±‚å’Œ:**",
    "softmax_probs": "**Softmaxæ¦‚ç‡:**",
    "probability_sum": "**æ¦‚ç‡å’Œ:**",
    "attention_visualization": "ğŸ‘ï¸ æ³¨æ„åŠ›å…³ç³»å¯è§†åŒ–",
    "attention_tip": "ğŸ’¡ **Tip:** æ³¨æ„åŠ›æƒé‡æ˜¾ç¤ºäº†æ¨¡å‹åœ¨å¤„ç†æ¯ä¸ªtokenæ—¶å¯¹å…¶ä»–tokençš„å…³æ³¨ç¨‹åº¦ã€‚é¢œè‰²è¶Šæ·±è¡¨ç¤ºæ³¨æ„åŠ›æƒé‡è¶Šé«˜ã€‚",
    "attention_heads": "**æ³¨æ„åŠ›å¤´æ•°é‡:**",
    "attention_matrix": "**æ³¨æ„åŠ›å¤´ {head_num} çš„æ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾:**",
    "attention_cell_desc": "æ¯ä¸ªå•å…ƒæ ¼è¡¨ç¤ºè¡Œtokenå¯¹åˆ—tokençš„æ³¨æ„åŠ›æƒé‡",
    "max_attention": "**æœ€é«˜æ³¨æ„åŠ›æƒé‡:** {max_attn:.4f} (Token {token_from} â†’ Token {token_to})",
    "final_vector": "æœ€ç»ˆå‘é‡è¡¨ç¤º",
    "vector_dimension": "**å‘é‡ç»´åº¦:**",
    "vector_first_20": "**å‘é‡å‰20ä¸ªå…ƒç´ :**",
    "vector_stats": "**å‘é‡ç»Ÿè®¡ä¿¡æ¯:**",
    "min_value": "æœ€å°å€¼",
    "max_value": "æœ€å¤§å€¼",
    "mean_value": "å¹³å‡å€¼",
    "std_value": "æ ‡å‡†å·®",
    "normalization_tip": "ğŸ’¡ **Tip:** å½’ä¸€åŒ–æ˜¯å°†å‘é‡ç¼©æ”¾åˆ°å›ºå®šèŒƒæ•°çš„è¿‡ç¨‹ï¼Œé€šå¸¸ä½¿ç”¨L2å½’ä¸€åŒ–ï¼ˆæ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼‰ã€‚å½’ä¸€åŒ–åçš„å‘é‡å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œä¾¿äºåç»­çš„ç›¸ä¼¼åº¦æ¯”è¾ƒå’Œè®¡ç®—ã€‚",
    "norm_before": "**å½’ä¸€åŒ–å‰å‘é‡èŒƒæ•°:**",
    "norm_after": "**å½’ä¸€åŒ–åå‘é‡èŒƒæ•°:**",
    "normalized_vector": "**å½’ä¸€åŒ–åå‘é‡å‰20ä¸ªå…ƒç´ :**",
    "norm_comparison": "**å½’ä¸€åŒ–å‰åå¯¹æ¯”:**",
    "before_normalization": "å½’ä¸€åŒ–å‰:",
    "after_normalization": "å½’ä¸€åŒ–å:",
    "correlation_tip": "ğŸ’¡ **Tip:** ç›¸å…³æ€§è®¡ç®—ç”¨äºè¡¡é‡è¾“å…¥æ–‡æœ¬ä¸å…¶ä»–æ–‡æœ¬æˆ–ç±»åˆ«çš„ç›¸ä¼¼ç¨‹åº¦ã€‚é€šå¸¸ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå€¼èŒƒå›´ä¸º[-1, 1]ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºç›¸ä¼¼åº¦è¶Šé«˜ã€‚",
    "correlation_with_categories": "**ä¸ç¤ºä¾‹ç±»åˆ«çš„ç›¸å…³æ€§:**",
    "most_relevant": "**æœ€ç›¸å…³ç±»åˆ«:** {most_relevant} (ç›¸ä¼¼åº¦: {similarity_value:.4f})",
    "classification_tip": "ğŸ’¡ **Tip:** BERTæ˜¯å¼ºå¤§çš„ç¼–ç å™¨æ¨¡å‹ï¼Œé€šè¿‡è¾“å‡ºçš„å‘é‡è¡¨ç¤ºå¯ä»¥ç”¨äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚æ–‡æœ¬åˆ†ç±»æ˜¯æœ€å¸¸è§çš„åº”ç”¨ä¹‹ä¸€ï¼Œç”¨äºå°†æ–‡æœ¬å½’ç±»åˆ°é¢„å®šä¹‰çš„ç±»åˆ«ä¸­ã€‚",
    "bert_analysis": "**BERTæ¨¡å‹åˆ†æç»“æœ:**",
    "bert_info": "BERTæ˜¯ç¼–ç å™¨æ¨¡å‹ï¼Œä¸æ”¯æŒæ–‡æœ¬ç”Ÿæˆï¼Œä½†å¯ä»¥ç”¨äºæ–‡æœ¬åˆ†ç±»ã€å‘é‡ç”Ÿæˆç­‰ä»»åŠ¡ã€‚\n\nå½“å‰å®ç°ä½¿ç”¨BERTè¿›è¡Œï¼š\n1. ä¸­æ–‡åˆ†è¯\n2. æ–‡æœ¬ç¼–ç \n3. å‘é‡ç”Ÿæˆ\n4. å‘é‡å½’ä¸€åŒ–\n5. ç›¸å…³æ€§è®¡ç®—",
    "vector_applications": "**è¾“å…¥æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºå¯ç”¨äºï¼š**",
    "similarity_calc": "- æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—",
    "text_classification": "- æ–‡æœ¬åˆ†ç±»",
    "information_retrieval": "- ä¿¡æ¯æ£€ç´¢",
    "clustering": "- èšç±»åˆ†æ",
    "recommendation": "- æ¨èç³»ç»Ÿ",
    "mcp_tip": "ğŸ’¡ **Tip:** MCP (Model Context Processing) æ˜¯æŒ‡æ¨¡å‹ä¸Šä¸‹æ–‡å¤„ç†ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹è¾“å…¥ï¼Œæå‡æ¨¡å‹ç†è§£èƒ½åŠ›å’Œç”Ÿæˆè´¨é‡ã€‚",
    "mcp_process": "MCPå¤„ç†æµç¨‹",
    "context_acquisition": "### 1. ä¸Šä¸‹æ–‡è·å–",
    "context_acquisition_desc": "- ä»å¯¹è¯å†å²ä¸­æå–ç›¸å…³ä¸Šä¸‹æ–‡\n- è¯†åˆ«å…³é”®ä¿¡æ¯å’Œä¸»é¢˜\n- è¿‡æ»¤æ— å…³å†…å®¹",
    "context_optimization": "### 2. ä¸Šä¸‹æ–‡ä¼˜åŒ–",
    "context_optimization_desc": "- é‡æ–°æ’åºä¸Šä¸‹æ–‡ä¿¡æ¯\n- å‹ç¼©é•¿ä¸Šä¸‹æ–‡\n- æ·»åŠ ä»»åŠ¡æŒ‡ä»¤",
    "context_injection": "### 3. ä¸Šä¸‹æ–‡æ³¨å…¥",
    "context_injection_desc": "- å°†ä¼˜åŒ–åçš„ä¸Šä¸‹æ–‡è¾“å…¥æ¨¡å‹\n- ç¡®ä¿ä¸Šä¸‹æ–‡ä¸å½“å‰æŸ¥è¯¢ç›¸å…³\n- æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦",
    "mcp_example": "MCPç¤ºä¾‹æ¼”ç¤º",
    "original_context": "**åŸå§‹ä¸Šä¸‹æ–‡:**",
    "optimized_context": "**ä¼˜åŒ–åä¸Šä¸‹æ–‡:**",
    "mcp_advantages": "**MCPä¼˜åŠ¿:**",
    "mcp_advantage1": "- æå‡æ¨¡å‹å¯¹é•¿ä¸Šä¸‹æ–‡çš„ç†è§£èƒ½åŠ›",
    "mcp_advantage2": "- å‡å°‘æ¨¡å‹æ³¨æ„åŠ›åˆ†æ•£",
    "mcp_advantage3": "- æé«˜ç”Ÿæˆå†…å®¹çš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§",
    "mcp_advantage4": "- é™ä½æ¨¡å‹è®¡ç®—æˆæœ¬",
    "skill_tip": "ğŸ’¡ **Tip:** Skillè°ƒç”¨å…è®¸æ¨¡å‹æ ¹æ®éœ€è¦ä½¿ç”¨å¤–éƒ¨å·¥å…·å’ŒAPIï¼Œæ‰©å±•æ¨¡å‹èƒ½åŠ›ï¼Œè§£å†³å¤æ‚é—®é¢˜ã€‚",
    "skill_process": "Skillè°ƒç”¨æµç¨‹",
    "intent_recognition": "### 1. æ„å›¾è¯†åˆ«",
    "intent_recognition_desc": "æ¨¡å‹è¯†åˆ«ç”¨æˆ·è¯·æ±‚éœ€è¦ä½¿ç”¨ç‰¹å®šæŠ€èƒ½",
    "skill_selection": "### 2. æŠ€èƒ½é€‰æ‹©",
    "skill_selection_desc": "æ ¹æ®è¯·æ±‚ç±»å‹é€‰æ‹©åˆé€‚çš„æŠ€èƒ½",
    "parameter_extraction": "### 3. å‚æ•°æå–",
    "parameter_extraction_desc": "ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æŠ€èƒ½æ‰€éœ€å‚æ•°",
    "skill_execution": "### 4. æŠ€èƒ½æ‰§è¡Œ",
    "skill_execution_desc": "è°ƒç”¨å¤–éƒ¨æŠ€èƒ½å¹¶è·å–ç»“æœ",
    "result_integration": "### 5. ç»“æœæ•´åˆ",
    "result_integration_desc": "å°†æŠ€èƒ½ç»“æœæ•´åˆåˆ°æ¨¡å‹å“åº”ä¸­",
    "skill_examples": "Skillç¤ºä¾‹",
    "available_skills": "**å¯ç”¨æŠ€èƒ½åˆ—è¡¨:**",
    "skill_demonstration": "æŠ€èƒ½è°ƒç”¨æ¼”ç¤º",
    "user_request": "**ç”¨æˆ·è¯·æ±‚:**",
    "selected_skill": "**é€‰æ‹©æŠ€èƒ½:**",
    "skill_parameters": "**æŠ€èƒ½å‚æ•°:**",
    "skill_result": "**æŠ€èƒ½ç»“æœ:**",
    "final_response": "**æœ€ç»ˆå“åº”:**",
    "rag_tip": "ğŸ’¡ **Tip:** RAG (Retrieval-Augmented Generation) ç»“åˆäº†ä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆå¼AIï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºæ¨¡å‹ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚",
    "rag_process": "RAGå¤„ç†æµç¨‹",
    "rag_components": "### RAGæ ¸å¿ƒç»„ä»¶",
    "retriever": "1. **æ£€ç´¢å™¨** - ä»æ–‡æ¡£åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯",
    "generator": "2. **ç”Ÿæˆå™¨** - åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå“åº”",
    "document_library": "3. **æ–‡æ¡£åº“** - å­˜å‚¨ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®",
    "indexer": "4. **ç´¢å¼•å™¨** - æ„å»ºé«˜æ•ˆçš„æ–‡æ¡£ç´¢å¼•",
    "rag_workflow": "### RAGå·¥ä½œæµç¨‹",
    "rag_workflow1": "1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢",
    "rag_workflow2": "2. å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º",
    "rag_workflow3": "3. æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£",
    "rag_workflow4": "4. å°†æ£€ç´¢ç»“æœä¸æŸ¥è¯¢ä¸€èµ·è¾“å…¥æ¨¡å‹",
    "rag_workflow5": "5. ç”Ÿæˆå¢å¼ºçš„å“åº”",
    "rag_visualization": "RAGæµç¨‹å¯è§†åŒ–",
    "rag_example": "RAGç¤ºä¾‹æ¼”ç¤º",
    "rag_query": "**ç”¨æˆ·æŸ¥è¯¢:**",
    "retrieved_documents": "**æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£:**",
    "rag_advantages": "**RAGä¼˜åŠ¿:**",
    "rag_advantage1": "- æé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œå¯é æ€§",
    "rag_advantage2": "- å…è®¸æ¨¡å‹è®¿é—®æœ€æ–°å’Œç‰¹å®šé¢†åŸŸçš„ä¿¡æ¯",
    "rag_advantage3": "- å‡å°‘æ¨¡å‹å¹»è§‰å’Œé”™è¯¯ä¿¡æ¯",
    "rag_advantage4": "- æ”¯æŒå¯¹ç”Ÿæˆå†…å®¹çš„å¼•ç”¨å’Œæº¯æº",
    "processing_completed": "å¤„ç†å®Œæˆï¼",
    "all_steps_completed": "æ‰€æœ‰å¤„ç†æ­¥éª¤å·²å®Œæˆï¼",
    "tokenization_complete": "å·²å®Œæˆåˆ†è¯å¤„ç†",
    "encoding_complete": "å·²å®Œæˆç¼–ç è½¬æ¢",
    "vectorization_complete": "å·²å®Œæˆå‘é‡åŒ–",
    "normalization_complete": "å·²å®Œæˆå½’ä¸€åŒ–",
    "correlation_complete": "å·²å®Œæˆç›¸å…³æ€§è®¡ç®—",
    "generation_complete": "å·²å®Œæˆç”Ÿæˆå“åº”",
    "mcp_complete": "å·²å®ŒæˆMCPå¤„ç†",
    "skill_complete": "å·²å®ŒæˆSkillè°ƒç”¨",
    "rag_complete": "å·²å®ŒæˆRAGæ¼”ç¤º"
  }
}
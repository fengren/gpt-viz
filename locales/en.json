{
  "page_title": "Transformer ChatGPT Visual",
  "title": "ü§ñ Transformer ChatGPT Visual",
  "sidebar_header": "Parameter Settings",
  "user_input": "Enter query:",
  "max_chars_help": "Maximum 200 characters",
  "temperature": "Temperature",
  "temperature_help": "Controls the randomness of generated text, higher values are more random",
  "top_p": "Top-p (Nucleus Sampling)",
  "top_p_help": "Controls the probability threshold for nucleus sampling",
  "top_k": "Top-k",
  "top_k_help": "Number of highest probability tokens to consider during generation",
  "max_new_tokens": "Max New Tokens",
  "max_new_tokens_help": "Maximum number of tokens to generate",
  "processing_steps": "Processing Steps",
  "basic_steps": "Basic Processing Steps",
  "tokenization": "1. Tokenization",
  "encoding": "2. Encoding",
  "vectorization": "3. Vectorization",
  "normalization": "4. Normalization",
  "correlation": "5. Correlation Calculation",
  "generation": "6. Generation",
  "advanced_features": "Advanced Features",
  "enable_advanced": "Enable Advanced Features",
  "mcp": "7. MCP (Model Context Processing)",
  "skill": "8. Skill (Tool Calling)",
  "rag": "9. RAG (Retrieval-Augmented Generation)",
  "process_button": "Process",
  "processing": "Processing...",
  "tokenization_tip": "üí° **Tip:** Tokenization is the process of breaking continuous text into meaningful basic units (tokens), which is the first step in NLP processing.",
  "original_input": "**Original Input:**",
  "tokenization_result": "**Tokenization Result:**",
  "tokenization_visualization": "**Tokenization Visualization:**",
  "encoding_tip": "üí° **Tip:** Encoding converts tokenization results into numerical IDs that the model can understand.",
  "token_ids": "**Token IDs:**",
  "token_id_mapping": "**Token to ID Mapping:**",
  "vectorization_tip": "üí° **Tip:** Vectorization converts discrete token IDs into continuous vector representations.",
  "token_to_vector": "Token to Vector Conversion Process",
  "word_embedding": "1. **Word Embedding Layer**: Each token ID is mapped to a fixed-dimensional vector through an embedding matrix",
  "positional_embedding": "2. **Positional Embedding**: Add positional information to help the model understand token order",
  "layer_norm": "3. **Layer Normalization**: Normalize vectors",
  "multi_head_attention": "4. **Multi-Head Attention**: Calculate relationships between tokens using self-attention mechanism",
  "feed_forward": "5. **Feed-Forward Network**: Apply non-linear transformation to attention output",
  "dot_product_visualization": "üî¢ Dot Product Calculation Visualization",
  "dot_product_desc": "Dot product is the core calculation in Transformer attention mechanism, used to measure the similarity between two vectors:",
  "vector_a": "**Vector A:**",
  "vector_b": "**Vector B:**",
  "dot_product_result": "**Dot Product Result:**",
  "dot_product_calc": "Calculation: (0.5 √ó 0.3) + (0.7 √ó 0.6) + (0.2 √ó 0.9) = 0.15 + 0.42 + 0.18 = 0.75",
  "softmax_activation": "üìà Softmax Activation Function",
  "softmax_tip": "üí° **Tip:** Softmax function converts a set of arbitrary real numbers into a probability distribution between 0 and 1, with all output values summing to 1.",
  "input_logits": "**Input Logits:**",
  "exponential_transform": "**Exponential Transformation:**",
  "sum_result": "**Sum:**",
  "softmax_probs": "**Softmax Probabilities:**",
  "probability_sum": "**Probability Sum:**",
  "attention_visualization": "üëÅÔ∏è Attention Relationship Visualization",
  "attention_tip": "üí° **Tip:** Attention weights show how much the model focuses on other tokens when processing each token. Darker colors indicate higher attention weights.",
  "attention_heads": "**Number of Attention Heads:**",
  "attention_matrix": "**Attention Weights Heatmap for Head {head_num}:**",
  "attention_cell_desc": "Each cell represents the attention weight from the row token to the column token",
  "max_attention": "**Maximum Attention Weight:** {max_attn:.4f} (Token {token_from} ‚Üí Token {token_to})",
  "final_vector": "Final Vector Representation",
  "vector_dimension": "**Vector Dimension:**",
  "vector_first_20": "**First 20 Vector Elements:**",
  "vector_stats": "**Vector Statistics:**",
  "min_value": "Min",
  "max_value": "Max",
  "mean_value": "Mean",
  "std_value": "Std",
  "normalization_tip": "üí° **Tip:** Normalization scales vectors to a fixed norm, usually using L2 normalization (Euclidean norm).",
  "norm_before": "**Vector Norm Before Normalization:**",
  "norm_after": "**Vector Norm After Normalization:**",
  "normalized_vector": "**Normalized Vector First 20 Elements:**",
  "norm_comparison": "**Normalization Comparison:**",
  "before_normalization": "Before Normalization:",
  "after_normalization": "After Normalization:",
  "correlation_tip": "üí° **Tip:** Correlation calculation measures the similarity between input text and other texts or categories.",
  "correlation_with_categories": "**Correlation with Example Categories:**",
  "most_relevant": "**Most Relevant Category:** {most_relevant} (Similarity: {similarity_value:.4f})",
  "classification_tip": "üí° **Tip:** BERT is a powerful encoder model that can be used for various downstream tasks through its output vector representations.",
  "bert_analysis": "**BERT Model Analysis Results:**",
  "bert_info": "BERT is an encoder model that does not support text generation, but can be used for text classification, vector generation, etc.\n\nCurrent implementation uses BERT for:\n1. Chinese tokenization\n2. Text encoding\n3. Vector generation\n4. Vector normalization\n5. Correlation calculation",
  "vector_applications": "**Input Text Vector Representation Can Be Used For:**",
  "similarity_calc": "- Text similarity calculation",
  "text_classification": "- Text classification",
  "information_retrieval": "- Information retrieval",
  "clustering": "- Clustering analysis",
  "recommendation": "- Recommendation systems",
  "mcp_tip": "üí° **Tip:** MCP (Model Context Processing) optimizes model inputs to improve understanding and generation quality.",
  "mcp_process": "MCP Processing Flow",
  "context_acquisition": "### 1. Context Acquisition",
  "context_acquisition_desc": "- Extract relevant context from dialogue history\n- Identify key information and topics\n- Filter irrelevant content",
  "context_optimization": "### 2. Context Optimization",
  "context_optimization_desc": "- Reorder context information\n- Compress long context\n- Add task instructions",
  "context_injection": "### 3. Context Injection",
  "context_injection_desc": "- Input optimized context into the model\n- Ensure context is relevant to current query\n- Control context length",
  "mcp_example": "MCP Example Demonstration",
  "original_context": "**Original Context:**",
  "optimized_context": "**Optimized Context:**",
  "mcp_advantages": "**MCP Advantages:**",
  "mcp_advantage1": "- Improve model understanding of long context",
  "mcp_advantage2": "- Reduce model attention dispersion",
  "mcp_advantage3": "- Improve relevance and accuracy of generated content",
  "mcp_advantage4": "- Reduce model computational cost",
  "skill_tip": "üí° **Tip:** Skill calling allows the model to use external tools and APIs as needed to extend its capabilities.",
  "skill_process": "Skill Calling Flow",
  "intent_recognition": "### 1. Intent Recognition",
  "intent_recognition_desc": "The model identifies that a specific skill is needed for the user's request",
  "skill_selection": "### 2. Skill Selection",
  "skill_selection_desc": "Select appropriate skills based on request type",
  "parameter_extraction": "### 3. Parameter Extraction",
  "parameter_extraction_desc": "Extract required parameters for the skill from user input",
  "skill_execution": "### 4. Skill Execution",
  "skill_execution_desc": "Call external skills and obtain results",
  "result_integration": "### 5. Result Integration",
  "result_integration_desc": "Integrate skill results into model response",
  "skill_examples": "Skill Examples",
  "available_skills": "**Available Skills List:**",
  "skill_demonstration": "Skill Calling Demonstration",
  "user_request": "**User Request:**",
  "selected_skill": "**Selected Skill:**",
  "skill_parameters": "**Skill Parameters:**",
  "skill_result": "**Skill Result:**",
  "final_response": "**Final Response:**",
  "rag_tip": "üí° **Tip:** RAG (Retrieval-Augmented Generation) combines information retrieval and generative AI to enhance the accuracy and reliability of model-generated content.",
  "rag_process": "RAG Processing Flow",
  "rag_components": "### RAG Core Components",
  "retriever": "1. **Retriever** - Retrieve relevant information from document library",
  "generator": "2. **Generator** - Generate responses based on retrieval results",
  "document_library": "3. **Document Library** - Store structured and unstructured data",
  "indexer": "4. **Indexer** - Build efficient document indexes",
  "rag_workflow": "### RAG Workflow",
  "rag_workflow1": "1. Receive user query",
  "rag_workflow2": "2. Convert query to vector representation",
  "rag_workflow3": "3. Retrieve relevant documents from query",
  "rag_workflow4": "4. Input retrieval results and query into model",
  "rag_workflow5": "5. Generate enhanced response",
  "rag_visualization": "RAG Flow Visualization",
  "rag_example": "RAG Example Demonstration",
  "rag_query": "**User Query:**",
  "retrieved_documents": "**Retrieved Relevant Documents:**",
  "rag_advantages": "**RAG Advantages:**",
  "rag_advantage1": "- Improve accuracy and reliability of generated content",
  "rag_advantage2": "- Allow models to access latest and domain-specific information",
  "rag_advantage3": "- Reduce model hallucinations and misinformation",
  "rag_advantage4": "- Support citation and traceability of generated content",
  "processing_completed": "Processing Completed!",
  "all_steps_completed": "All processing steps have been completed!",
  "tokenization_complete": "Completed Tokenization",
  "encoding_complete": "Completed Encoding",
  "vectorization_complete": "Completed Vectorization",
  "normalization_complete": "Completed Normalization",
  "correlation_complete": "Completed Correlation Calculation",
  "generation_complete": "Completed Generation",
  "mcp_complete": "Completed MCP Processing",
  "skill_complete": "Completed Skill Calling",
  "rag_complete": "Completed RAG Demonstration"
}